{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3503ea",
   "metadata": {},
   "source": [
    "## Final scoring Model Methods\n",
    "\n",
    "In this notebook I have finalized how/what features will be used in our scoring model and get the finalized weights and what the output of the model will do. With group discussions and from previous testing of the models we removed the hotspot score since it was not listed as an important feature and we brought back sin/cos hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5806ba26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter.filedialog import asksaveasfilename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581966f",
   "metadata": {},
   "source": [
    "## XGBoost with Boroughs sin/cos hour and no hotspot score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29758dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:/diksha/Summer Sem/DataAnalysis/Data/clean with features for scoring/Cleaned_Jan_Feb_with_Hotness_and_trip_duration.csv\n",
      "Shape: (5609910, 30)\n",
      "\n",
      "Time-Based Evaluation XGBoost (Train: Jan, Test: Feb):\n",
      "R¬≤ Score: 0.4335\n",
      "MAE: 0.1715\n",
      "\n",
      "Top Features:\n",
      "dropoff_borough_EWR          0.309659\n",
      "fare_per_mile                0.222582\n",
      "is_airport_trip              0.091446\n",
      "trip_duration_variability    0.085614\n",
      "dropoff_borough_Brooklyn     0.059010\n",
      "cos_hour                     0.050330\n",
      "pickup_borough_Queens        0.038808\n",
      "dropoff_borough_Queens       0.037615\n",
      "sin_hour                     0.027236\n",
      "pickup_borough_Brooklyn      0.025678\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned and merged file\n",
    "Tk().withdraw()\n",
    "file_path = askopenfilename(title=\"Select Cleaned Merged CSV with Features\")\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Loaded:\", file_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Log-transform target for regression stability\n",
    "df['log_fare_per_minute'] = np.log1p(df['fare_per_minute'])\n",
    "\n",
    "# Also log-transform fare_per_mile if not already done\n",
    "#df['log_fare_per_mile'] = np.log1p(df['fare_per_mile'])\n",
    "\n",
    "# Final features (after removing boroughs and time_of_day)\n",
    "categorical_cols = ['is_airport_trip', 'pickup_borough', 'dropoff_borough']\n",
    "numeric_cols = [\n",
    "    #'fare_per_mile',\n",
    "    'dropoff_zone_hotness',\n",
    "    'trip_duration_variability',\n",
    "    #'hotspot_score',  \n",
    "    'sin_hour',\n",
    "    'cos_hour'\n",
    "]\n",
    "feature_cols = categorical_cols + numeric_cols\n",
    "\n",
    "# Preprocess datetime and filter rows\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "df = df.dropna(subset=['fare_per_minute'])  # Drop rows with missing original target\n",
    "\n",
    "# Encode sin/cos hour\n",
    "df['sin_hour'] = np.sin(2 * np.pi * df['pickup_hour'] / 24)\n",
    "df['cos_hour'] = np.cos(2 * np.pi * df['pickup_hour'] / 24)\n",
    "df.drop(columns=['pickup_hour', 'time_of_day'], inplace=True, errors='ignore')\n",
    "\n",
    "# Time-based split (Jan ‚Üí train, Feb ‚Üí test)\n",
    "train_df = df[df['pickup_date'].dt.month == 1].copy()\n",
    "test_df = df[df['pickup_date'].dt.month == 2].copy()\n",
    "\n",
    "# Preprocess categorical features\n",
    "X_train_cat = pd.get_dummies(train_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = pd.get_dummies(test_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = X_test_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n",
    "\n",
    "# Final feature matrices\n",
    "X_train = pd.concat([train_df[numeric_cols].reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([test_df[numeric_cols].reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Targets\n",
    "y_train = train_df['log_fare_per_minute']  # log-transformed for training\n",
    "y_test = test_df['fare_per_minute']        # original scale for evaluation\n",
    "\n",
    "# Train model\n",
    "model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and invert log transformation\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # convert back to original scale\n",
    "\n",
    "# Evaluate\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Output results\n",
    "print(f\"\\nTime-Based Evaluation XGBoost (Train: Jan, Test: Feb):\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(\"\\nTop Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a4ee0",
   "metadata": {},
   "source": [
    "## LightGBM with Boroughs sin/cos hour and no hotspot score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:/diksha/Summer Sem/DataAnalysis/Data/clean with features for scoring/Cleaned_Jan_Feb_with_Hotness_and_trip_duration.csv\n",
      "Shape: (5609910, 30)\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 2871008, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 0.806685\n",
      "\n",
      "Time-Based Evaluation LightGBM (Train: Jan, Test: Feb):\n",
      "R¬≤ Score: 0.4167\n",
      "MAE: 0.1742\n",
      "\n",
      "Top Features:\n",
      "fare_per_mile                1211\n",
      "trip_duration_variability     506\n",
      "dropoff_zone_hotness          370\n",
      "cos_hour                      241\n",
      "sin_hour                      226\n",
      "is_airport_trip               104\n",
      "pickup_borough_Queens          74\n",
      "dropoff_borough_EWR            61\n",
      "dropoff_borough_Manhattan      61\n",
      "dropoff_borough_Brooklyn       48\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned and merged file\n",
    "Tk().withdraw()\n",
    "file_path = askopenfilename(title=\"Select Cleaned Merged CSV with Features \")\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Loaded:\", file_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Log-transform target for regression stability\n",
    "df['log_fare_per_minute'] = np.log1p(df['fare_per_minute'])\n",
    "\n",
    "# Log-transform fare_per_mile for modeling\n",
    "#df['log_fare_per_mile'] = np.log1p(df['fare_per_mile'])\n",
    "\n",
    "# Feature lists\n",
    "categorical_cols = ['is_airport_trip', 'pickup_borough', 'dropoff_borough']\n",
    "numeric_cols = [\n",
    "    #'fare_per_mile',\n",
    "    'dropoff_zone_hotness',\n",
    "    'trip_duration_variability',\n",
    "    #'hotspot_score',\n",
    "    'sin_hour',\n",
    "    'cos_hour'\n",
    "]\n",
    "feature_cols = categorical_cols + numeric_cols\n",
    "\n",
    "# Date/time handling\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "df = df.dropna(subset=['fare_per_minute'])\n",
    "\n",
    "# Add sin/cos hour encodings\n",
    "df['sin_hour'] = np.sin(2 * np.pi * df['pickup_hour'] / 24)\n",
    "df['cos_hour'] = np.cos(2 * np.pi * df['pickup_hour'] / 24)\n",
    "df.drop(columns=['pickup_hour', 'time_of_day'], inplace=True, errors='ignore')\n",
    "\n",
    "# Train/test split\n",
    "train_df = df[df['pickup_date'].dt.month == 1].copy()\n",
    "test_df = df[df['pickup_date'].dt.month == 2].copy()\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "X_train_cat = pd.get_dummies(train_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = pd.get_dummies(test_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = X_test_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n",
    "\n",
    "# Final input matrices\n",
    "X_train = pd.concat([train_df[numeric_cols].reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([test_df[numeric_cols].reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Targets\n",
    "y_train = train_df['log_fare_per_minute']\n",
    "y_test = test_df['fare_per_minute']  # Original scale for evaluation\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_model = LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and invert log transform\n",
    "y_pred_log = lgb_model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# Evaluate performance\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "feature_importance = pd.Series(lgb_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Output\n",
    "print(f\"\\nTime-Based Evaluation LightGBM (Train: Jan, Test: Feb):\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(\"\\nTop Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2ead3",
   "metadata": {},
   "source": [
    "## To  Get Feature Importance Values\n",
    "\n",
    "since we have both lightgbm and xgboost the best way to derive the weights is to normalize and avg the features\n",
    "\n",
    "We can normalize each models importance (scale them to sum of 1)  and the avg them across the models (this was taken from chatgpt) once we get this we can use combined weights that gives the final weight (%) to apply to each feature in the scoring equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ea4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Combined Feature Importances:\n",
      "\n",
      "fare_per_mile                0.319940\n",
      "dropoff_borough_EWR          0.165339\n",
      "trip_duration_variability    0.129988\n",
      "cos_hour                     0.066688\n",
      "dropoff_zone_hotness         0.063749\n",
      "is_airport_trip              0.063642\n",
      "sin_hour                     0.052557\n",
      "dropoff_borough_Brooklyn     0.037775\n",
      "pickup_borough_Queens        0.032154\n",
      "dropoff_borough_Queens       0.018808\n",
      "pickup_borough_Brooklyn      0.012839\n",
      "dropoff_borough_Manhattan    0.010510\n",
      "Name: avg_importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# XGBoost importances from the model (already normalized)\n",
    "xgb_importances = {\n",
    "    'dropoff_borough_EWR': 0.309659,\n",
    "    #'fare_per_mile': 0.222582,\n",
    "    'is_airport_trip': 0.091446,\n",
    "    'trip_duration_variability': 0.085614,\n",
    "    'dropoff_borough_Brooklyn': 0.059010,\n",
    "    'cos_hour': 0.050330,\n",
    "    'pickup_borough_Queens': 0.038808,\n",
    "    'dropoff_borough_Queens': 0.037615,\n",
    "    'sin_hour': 0.027236,\n",
    "    'pickup_borough_Brooklyn': 0.025678,\n",
    "    'dropoff_zone_hotness': 0.0\n",
    "}\n",
    "\n",
    "# LightGBM raw split count importances from the model\n",
    "lgb_importances = {\n",
    "    #'fare_per_mile': 1211,\n",
    "    'trip_duration_variability': 506,\n",
    "    'dropoff_zone_hotness': 370,\n",
    "    'cos_hour': 241,\n",
    "    'sin_hour': 226,\n",
    "    'is_airport_trip': 104,\n",
    "    'pickup_borough_Queens': 74,\n",
    "    'dropoff_borough_EWR': 61,\n",
    "    'dropoff_borough_Manhattan': 61,\n",
    "    'dropoff_borough_Brooklyn': 48\n",
    "}\n",
    "\n",
    "# Convert to Series\n",
    "xgb_series = pd.Series(xgb_importances)\n",
    "lgb_series = pd.Series(lgb_importances)\n",
    "\n",
    "# Normalize LightGBM to sum to 1\n",
    "lgb_normalized = lgb_series / lgb_series.sum()\n",
    "\n",
    "# Combine and average (only overlapping features will be averaged)\n",
    "combined_df = pd.concat([xgb_series, lgb_normalized], axis=1, keys=['xgb', 'lgb_norm']).fillna(0)\n",
    "combined_df['avg_importance'] = combined_df.mean(axis=1)\n",
    "\n",
    "# Sort by average importance\n",
    "final_weights = combined_df['avg_importance'].sort_values(ascending=False)\n",
    "\n",
    "# Display result\n",
    "print(\"\\n Final Combined Feature Importances:\\n\")\n",
    "print(final_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70963e9",
   "metadata": {},
   "source": [
    "These columns like pickup_borough_Queens or dropoff_borough_Brooklyn are how the model understands where the trip starts or ends.\n",
    "\n",
    "They‚Äôre created from the pickup_borough and dropoff_borough values we had in the data.\n",
    "\n",
    "We need to keep them in the scoring model because the model learned to associate certain boroughs with higher or lower profitability ‚Äî and each of these one-hot columns has a weight based on how much it contributed during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9654e",
   "metadata": {},
   "source": [
    "## Function for the Scoring Function\n",
    "\n",
    "This is the the final feature to now output the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd9aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of predicted scores:\n",
      "   predicted_score  final_score\n",
      "0        38.117309     0.107897\n",
      "1        17.270233     0.048792\n",
      "2        33.225518     0.094028\n",
      "3         1.928905     0.005297\n",
      "4        38.053078     0.107715\n",
      "\n",
      "Top 5 Most Profitable Trips:\n",
      "              tpep_pickup_datetime      tpep_dropoff_datetime  trip_distance  \\\n",
      "1799836  2023-02-19 01:39:07-05:00  2023-02-19 01:40:37-05:00           0.04   \n",
      "415841   2023-02-05 01:29:56-05:00  2023-02-05 01:31:41-05:00           0.10   \n",
      "2748127  2023-01-01 01:47:04-05:00  2023-01-01 01:48:55-05:00           0.10   \n",
      "5364675  2023-01-29 01:44:21-05:00  2023-01-29 01:45:53-05:00           0.10   \n",
      "416377   2023-02-05 01:39:05-05:00  2023-02-05 01:41:33-05:00           0.10   \n",
      "\n",
      "         fare_amount  trip_duration_min pickup_date  pickup_day_of_week  \\\n",
      "1799836          3.7           1.500000  2023-02-19                   6   \n",
      "415841           3.7           1.750000  2023-02-05                   6   \n",
      "2748127          3.7           1.850000  2023-01-01                   6   \n",
      "5364675          3.7           1.533333  2023-01-29                   6   \n",
      "416377           3.7           2.466667  2023-02-05                   6   \n",
      "\n",
      "        droppoff_date pickup_borough   pickup_zone  ...  sin_hour  cos_hour  \\\n",
      "1799836    2023-02-19      Manhattan  East Village  ...  0.258819  0.965926   \n",
      "415841     2023-02-05      Manhattan  East Village  ...  0.258819  0.965926   \n",
      "2748127    2023-01-01      Manhattan  East Village  ...  0.258819  0.965926   \n",
      "5364675    2023-01-29      Manhattan  East Village  ...  0.258819  0.965926   \n",
      "416377     2023-02-05      Manhattan  East Village  ...  0.258819  0.965926   \n",
      "\n",
      "        dropoff_borough_EWR dropoff_borough_Brooklyn  pickup_borough_Queens  \\\n",
      "1799836                   0                        0                      0   \n",
      "415841                    0                        0                      0   \n",
      "2748127                   0                        0                      0   \n",
      "5364675                   0                        0                      0   \n",
      "416377                    0                        0                      0   \n",
      "\n",
      "         dropoff_borough_Queens  pickup_borough_Brooklyn  \\\n",
      "1799836                       0                        0   \n",
      "415841                        0                        0   \n",
      "2748127                       0                        0   \n",
      "5364675                       0                        0   \n",
      "416377                        0                        0   \n",
      "\n",
      "         dropoff_borough_Manhattan predicted_score  final_score  \n",
      "1799836                          0      352.775507     1.000000  \n",
      "415841                           0      335.018837     0.949657  \n",
      "2748127                          0      335.018837     0.949657  \n",
      "5364675                          0      335.018837     0.949657  \n",
      "416377                           0      335.018837     0.949657  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "\n",
      "Bottom 5 Least Profitable Trips:\n",
      "              tpep_pickup_datetime      tpep_dropoff_datetime  trip_distance  \\\n",
      "2439746  2023-02-25 18:36:51-05:00  2023-02-25 19:18:46-05:00           19.4   \n",
      "2189341  2023-02-23 14:02:31-05:00  2023-02-23 14:41:19-05:00            4.2   \n",
      "2104189  2023-02-22 16:42:25-05:00  2023-02-22 19:20:19-05:00           17.0   \n",
      "3433171  2023-01-09 13:10:09-05:00  2023-01-09 14:57:41-05:00           14.7   \n",
      "2844813  2023-01-02 17:01:51-05:00  2023-01-02 17:39:43-05:00           11.5   \n",
      "\n",
      "         fare_amount  trip_duration_min pickup_date  pickup_day_of_week  \\\n",
      "2439746          3.0          41.916667  2023-02-25                   5   \n",
      "2189341          3.0          38.800000  2023-02-23                   3   \n",
      "2104189         21.5         157.900000  2023-02-22                   2   \n",
      "3433171         15.2         107.533333  2023-01-09                   0   \n",
      "2844813         18.2          37.866667  2023-01-02                   0   \n",
      "\n",
      "        droppoff_date pickup_borough              pickup_zone  ...  sin_hour  \\\n",
      "2439746    2023-02-25      Manhattan    Upper East Side North  ... -1.000000   \n",
      "2189341    2023-02-23      Manhattan  Greenwich Village South  ... -0.500000   \n",
      "2104189    2023-02-22       Brooklyn   East Flatbush/Farragut  ... -0.866025   \n",
      "3433171    2023-01-09         Queens                  Jamaica  ... -0.258819   \n",
      "2844813    2023-01-02         Queens             Forest Hills  ... -0.965926   \n",
      "\n",
      "             cos_hour dropoff_borough_EWR dropoff_borough_Brooklyn  \\\n",
      "2439746 -1.836970e-16                   0                        0   \n",
      "2189341 -8.660254e-01                   0                        0   \n",
      "2104189 -5.000000e-01                   0                        0   \n",
      "3433171 -9.659258e-01                   0                        0   \n",
      "2844813 -2.588190e-01                   0                        0   \n",
      "\n",
      "         pickup_borough_Queens  dropoff_borough_Queens  \\\n",
      "2439746                      0                       0   \n",
      "2189341                      0                       0   \n",
      "2104189                      0                       0   \n",
      "3433171                      0                       0   \n",
      "2844813                      0                       0   \n",
      "\n",
      "         pickup_borough_Brooklyn  dropoff_borough_Manhattan predicted_score  \\\n",
      "2439746                        0                          0        0.060560   \n",
      "2189341                        0                          0        0.144497   \n",
      "2104189                        0                          0        0.325770   \n",
      "3433171                        0                          0        0.380302   \n",
      "2844813                        0                          0        0.438314   \n",
      "\n",
      "         final_score  \n",
      "2439746     0.000000  \n",
      "2189341     0.000238  \n",
      "2104189     0.000752  \n",
      "3433171     0.000907  \n",
      "2844813     0.001071  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Final combined weights (replace with values from your final feature importance)\n",
    "combined_weights = {\n",
    "    #'fare_per_mile': 0.319940,\n",
    "    'dropoff_borough_EWR': 0.165339,\n",
    "    'trip_duration_variability': 0.129988,\n",
    "    'cos_hour': 0.066688,\n",
    "    'dropoff_zone_hotness': 0.063749,\n",
    "    'is_airport_trip': 0.063642,\n",
    "    'sin_hour': 0.052557,\n",
    "    'dropoff_borough_Brooklyn': 0.037775,\n",
    "    'pickup_borough_Queens': 0.032154,\n",
    "    'dropoff_borough_Queens': 0.018808,\n",
    "    'pickup_borough_Brooklyn': 0.012839,\n",
    "    'dropoff_borough_Manhattan': 0.010510\n",
    "}\n",
    "\n",
    "#  Create a copy of the working DataFrame\n",
    "df_scoring = df.copy()\n",
    "\n",
    "#  Make sure one-hot encoded features exist (e.g., for boroughs)\n",
    "for feature in combined_weights:\n",
    "    if feature not in df_scoring.columns:\n",
    "        df_scoring[feature] = 0  # Fill missing one-hot columns with 0s\n",
    "\n",
    "#  Define scoring function\n",
    "def calculate_score(row, weights):\n",
    "    score = 0\n",
    "    for feature, weight in weights.items():\n",
    "        score += row.get(feature, 0) * weight\n",
    "    return score\n",
    "\n",
    "#  Apply scoring function\n",
    "df_scoring['predicted_score'] = df_scoring.apply(lambda row: calculate_score(row, combined_weights), axis=1)\n",
    "\n",
    "#  Normalize predicted score to 0‚Äì1\n",
    "scaler = MinMaxScaler()\n",
    "df_scoring['final_score'] = scaler.fit_transform(df_scoring[['predicted_score']])\n",
    "\n",
    "#  Preview scores\n",
    "print(\"\\nPreview of predicted scores:\")\n",
    "print(df_scoring[['predicted_score', 'final_score']].head())\n",
    "\n",
    "#  show best/worst trips\n",
    "print(\"\\nTop 5 Most Profitable Trips:\")\n",
    "print(df_scoring.sort_values('final_score', ascending=False).head())\n",
    "\n",
    "print(\"\\nBottom 5 Least Profitable Trips:\")\n",
    "print(df_scoring.sort_values('final_score').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7874f5",
   "metadata": {},
   "source": [
    "# Display final results (top 5 for good and bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfca2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Top 5 Most Profitable Trips\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0cedf\">\n",
       "  <caption>Top 5 Trips</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0cedf_level0_col0\" class=\"col_heading level0 col0\" >tpep_pickup_datetime</th>\n",
       "      <th id=\"T_0cedf_level0_col1\" class=\"col_heading level0 col1\" >tpep_dropoff_datetime</th>\n",
       "      <th id=\"T_0cedf_level0_col2\" class=\"col_heading level0 col2\" >trip_distance</th>\n",
       "      <th id=\"T_0cedf_level0_col3\" class=\"col_heading level0 col3\" >fare_amount</th>\n",
       "      <th id=\"T_0cedf_level0_col4\" class=\"col_heading level0 col4\" >trip_duration_min</th>\n",
       "      <th id=\"T_0cedf_level0_col5\" class=\"col_heading level0 col5\" >pickup_borough</th>\n",
       "      <th id=\"T_0cedf_level0_col6\" class=\"col_heading level0 col6\" >pickup_zone</th>\n",
       "      <th id=\"T_0cedf_level0_col7\" class=\"col_heading level0 col7\" >dropoff_borough</th>\n",
       "      <th id=\"T_0cedf_level0_col8\" class=\"col_heading level0 col8\" >dropoff_zone</th>\n",
       "      <th id=\"T_0cedf_level0_col9\" class=\"col_heading level0 col9\" >predicted_score</th>\n",
       "      <th id=\"T_0cedf_level0_col10\" class=\"col_heading level0 col10\" >final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0cedf_level0_row0\" class=\"row_heading level0 row0\" >1799836</th>\n",
       "      <td id=\"T_0cedf_row0_col0\" class=\"data row0 col0\" >2023-02-19 01:39:07-05:00</td>\n",
       "      <td id=\"T_0cedf_row0_col1\" class=\"data row0 col1\" >2023-02-19 01:40:37-05:00</td>\n",
       "      <td id=\"T_0cedf_row0_col2\" class=\"data row0 col2\" >0.04</td>\n",
       "      <td id=\"T_0cedf_row0_col3\" class=\"data row0 col3\" >$3.70</td>\n",
       "      <td id=\"T_0cedf_row0_col4\" class=\"data row0 col4\" >1.5 min</td>\n",
       "      <td id=\"T_0cedf_row0_col5\" class=\"data row0 col5\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row0_col6\" class=\"data row0 col6\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row0_col7\" class=\"data row0 col7\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row0_col8\" class=\"data row0 col8\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row0_col9\" class=\"data row0 col9\" >352.78</td>\n",
       "      <td id=\"T_0cedf_row0_col10\" class=\"data row0 col10\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cedf_level0_row1\" class=\"row_heading level0 row1\" >415841</th>\n",
       "      <td id=\"T_0cedf_row1_col0\" class=\"data row1 col0\" >2023-02-05 01:29:56-05:00</td>\n",
       "      <td id=\"T_0cedf_row1_col1\" class=\"data row1 col1\" >2023-02-05 01:31:41-05:00</td>\n",
       "      <td id=\"T_0cedf_row1_col2\" class=\"data row1 col2\" >0.10</td>\n",
       "      <td id=\"T_0cedf_row1_col3\" class=\"data row1 col3\" >$3.70</td>\n",
       "      <td id=\"T_0cedf_row1_col4\" class=\"data row1 col4\" >1.8 min</td>\n",
       "      <td id=\"T_0cedf_row1_col5\" class=\"data row1 col5\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row1_col6\" class=\"data row1 col6\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row1_col7\" class=\"data row1 col7\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row1_col8\" class=\"data row1 col8\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row1_col9\" class=\"data row1 col9\" >335.02</td>\n",
       "      <td id=\"T_0cedf_row1_col10\" class=\"data row1 col10\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cedf_level0_row2\" class=\"row_heading level0 row2\" >2748127</th>\n",
       "      <td id=\"T_0cedf_row2_col0\" class=\"data row2 col0\" >2023-01-01 01:47:04-05:00</td>\n",
       "      <td id=\"T_0cedf_row2_col1\" class=\"data row2 col1\" >2023-01-01 01:48:55-05:00</td>\n",
       "      <td id=\"T_0cedf_row2_col2\" class=\"data row2 col2\" >0.10</td>\n",
       "      <td id=\"T_0cedf_row2_col3\" class=\"data row2 col3\" >$3.70</td>\n",
       "      <td id=\"T_0cedf_row2_col4\" class=\"data row2 col4\" >1.9 min</td>\n",
       "      <td id=\"T_0cedf_row2_col5\" class=\"data row2 col5\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row2_col6\" class=\"data row2 col6\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row2_col7\" class=\"data row2 col7\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row2_col8\" class=\"data row2 col8\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row2_col9\" class=\"data row2 col9\" >335.02</td>\n",
       "      <td id=\"T_0cedf_row2_col10\" class=\"data row2 col10\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cedf_level0_row3\" class=\"row_heading level0 row3\" >5364675</th>\n",
       "      <td id=\"T_0cedf_row3_col0\" class=\"data row3 col0\" >2023-01-29 01:44:21-05:00</td>\n",
       "      <td id=\"T_0cedf_row3_col1\" class=\"data row3 col1\" >2023-01-29 01:45:53-05:00</td>\n",
       "      <td id=\"T_0cedf_row3_col2\" class=\"data row3 col2\" >0.10</td>\n",
       "      <td id=\"T_0cedf_row3_col3\" class=\"data row3 col3\" >$3.70</td>\n",
       "      <td id=\"T_0cedf_row3_col4\" class=\"data row3 col4\" >1.5 min</td>\n",
       "      <td id=\"T_0cedf_row3_col5\" class=\"data row3 col5\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row3_col6\" class=\"data row3 col6\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row3_col7\" class=\"data row3 col7\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row3_col8\" class=\"data row3 col8\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row3_col9\" class=\"data row3 col9\" >335.02</td>\n",
       "      <td id=\"T_0cedf_row3_col10\" class=\"data row3 col10\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cedf_level0_row4\" class=\"row_heading level0 row4\" >416377</th>\n",
       "      <td id=\"T_0cedf_row4_col0\" class=\"data row4 col0\" >2023-02-05 01:39:05-05:00</td>\n",
       "      <td id=\"T_0cedf_row4_col1\" class=\"data row4 col1\" >2023-02-05 01:41:33-05:00</td>\n",
       "      <td id=\"T_0cedf_row4_col2\" class=\"data row4 col2\" >0.10</td>\n",
       "      <td id=\"T_0cedf_row4_col3\" class=\"data row4 col3\" >$3.70</td>\n",
       "      <td id=\"T_0cedf_row4_col4\" class=\"data row4 col4\" >2.5 min</td>\n",
       "      <td id=\"T_0cedf_row4_col5\" class=\"data row4 col5\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row4_col6\" class=\"data row4 col6\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row4_col7\" class=\"data row4 col7\" >Manhattan</td>\n",
       "      <td id=\"T_0cedf_row4_col8\" class=\"data row4 col8\" >East Village</td>\n",
       "      <td id=\"T_0cedf_row4_col9\" class=\"data row4 col9\" >335.02</td>\n",
       "      <td id=\"T_0cedf_row4_col10\" class=\"data row4 col10\" >0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eb9fd20290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¥ Bottom 5 Least Profitable Trips\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7ed90\">\n",
       "  <caption>Bottom 5 Trips</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7ed90_level0_col0\" class=\"col_heading level0 col0\" >tpep_pickup_datetime</th>\n",
       "      <th id=\"T_7ed90_level0_col1\" class=\"col_heading level0 col1\" >tpep_dropoff_datetime</th>\n",
       "      <th id=\"T_7ed90_level0_col2\" class=\"col_heading level0 col2\" >trip_distance</th>\n",
       "      <th id=\"T_7ed90_level0_col3\" class=\"col_heading level0 col3\" >fare_amount</th>\n",
       "      <th id=\"T_7ed90_level0_col4\" class=\"col_heading level0 col4\" >trip_duration_min</th>\n",
       "      <th id=\"T_7ed90_level0_col5\" class=\"col_heading level0 col5\" >pickup_borough</th>\n",
       "      <th id=\"T_7ed90_level0_col6\" class=\"col_heading level0 col6\" >pickup_zone</th>\n",
       "      <th id=\"T_7ed90_level0_col7\" class=\"col_heading level0 col7\" >dropoff_borough</th>\n",
       "      <th id=\"T_7ed90_level0_col8\" class=\"col_heading level0 col8\" >dropoff_zone</th>\n",
       "      <th id=\"T_7ed90_level0_col9\" class=\"col_heading level0 col9\" >predicted_score</th>\n",
       "      <th id=\"T_7ed90_level0_col10\" class=\"col_heading level0 col10\" >final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ed90_level0_row0\" class=\"row_heading level0 row0\" >2439746</th>\n",
       "      <td id=\"T_7ed90_row0_col0\" class=\"data row0 col0\" >2023-02-25 18:36:51-05:00</td>\n",
       "      <td id=\"T_7ed90_row0_col1\" class=\"data row0 col1\" >2023-02-25 19:18:46-05:00</td>\n",
       "      <td id=\"T_7ed90_row0_col2\" class=\"data row0 col2\" >19.40</td>\n",
       "      <td id=\"T_7ed90_row0_col3\" class=\"data row0 col3\" >$3.00</td>\n",
       "      <td id=\"T_7ed90_row0_col4\" class=\"data row0 col4\" >41.9 min</td>\n",
       "      <td id=\"T_7ed90_row0_col5\" class=\"data row0 col5\" >Manhattan</td>\n",
       "      <td id=\"T_7ed90_row0_col6\" class=\"data row0 col6\" >Upper East Side North</td>\n",
       "      <td id=\"T_7ed90_row0_col7\" class=\"data row0 col7\" >EWR</td>\n",
       "      <td id=\"T_7ed90_row0_col8\" class=\"data row0 col8\" >Newark Airport</td>\n",
       "      <td id=\"T_7ed90_row0_col9\" class=\"data row0 col9\" >0.06</td>\n",
       "      <td id=\"T_7ed90_row0_col10\" class=\"data row0 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ed90_level0_row1\" class=\"row_heading level0 row1\" >2189341</th>\n",
       "      <td id=\"T_7ed90_row1_col0\" class=\"data row1 col0\" >2023-02-23 14:02:31-05:00</td>\n",
       "      <td id=\"T_7ed90_row1_col1\" class=\"data row1 col1\" >2023-02-23 14:41:19-05:00</td>\n",
       "      <td id=\"T_7ed90_row1_col2\" class=\"data row1 col2\" >4.20</td>\n",
       "      <td id=\"T_7ed90_row1_col3\" class=\"data row1 col3\" >$3.00</td>\n",
       "      <td id=\"T_7ed90_row1_col4\" class=\"data row1 col4\" >38.8 min</td>\n",
       "      <td id=\"T_7ed90_row1_col5\" class=\"data row1 col5\" >Manhattan</td>\n",
       "      <td id=\"T_7ed90_row1_col6\" class=\"data row1 col6\" >Greenwich Village South</td>\n",
       "      <td id=\"T_7ed90_row1_col7\" class=\"data row1 col7\" >Brooklyn</td>\n",
       "      <td id=\"T_7ed90_row1_col8\" class=\"data row1 col8\" >Stuyvesant Heights</td>\n",
       "      <td id=\"T_7ed90_row1_col9\" class=\"data row1 col9\" >0.14</td>\n",
       "      <td id=\"T_7ed90_row1_col10\" class=\"data row1 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ed90_level0_row2\" class=\"row_heading level0 row2\" >2104189</th>\n",
       "      <td id=\"T_7ed90_row2_col0\" class=\"data row2 col0\" >2023-02-22 16:42:25-05:00</td>\n",
       "      <td id=\"T_7ed90_row2_col1\" class=\"data row2 col1\" >2023-02-22 19:20:19-05:00</td>\n",
       "      <td id=\"T_7ed90_row2_col2\" class=\"data row2 col2\" >17.00</td>\n",
       "      <td id=\"T_7ed90_row2_col3\" class=\"data row2 col3\" >$21.50</td>\n",
       "      <td id=\"T_7ed90_row2_col4\" class=\"data row2 col4\" >157.9 min</td>\n",
       "      <td id=\"T_7ed90_row2_col5\" class=\"data row2 col5\" >Brooklyn</td>\n",
       "      <td id=\"T_7ed90_row2_col6\" class=\"data row2 col6\" >East Flatbush/Farragut</td>\n",
       "      <td id=\"T_7ed90_row2_col7\" class=\"data row2 col7\" >Brooklyn</td>\n",
       "      <td id=\"T_7ed90_row2_col8\" class=\"data row2 col8\" >Ocean Parkway South</td>\n",
       "      <td id=\"T_7ed90_row2_col9\" class=\"data row2 col9\" >0.33</td>\n",
       "      <td id=\"T_7ed90_row2_col10\" class=\"data row2 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ed90_level0_row3\" class=\"row_heading level0 row3\" >3433171</th>\n",
       "      <td id=\"T_7ed90_row3_col0\" class=\"data row3 col0\" >2023-01-09 13:10:09-05:00</td>\n",
       "      <td id=\"T_7ed90_row3_col1\" class=\"data row3 col1\" >2023-01-09 14:57:41-05:00</td>\n",
       "      <td id=\"T_7ed90_row3_col2\" class=\"data row3 col2\" >14.70</td>\n",
       "      <td id=\"T_7ed90_row3_col3\" class=\"data row3 col3\" >$15.20</td>\n",
       "      <td id=\"T_7ed90_row3_col4\" class=\"data row3 col4\" >107.5 min</td>\n",
       "      <td id=\"T_7ed90_row3_col5\" class=\"data row3 col5\" >Queens</td>\n",
       "      <td id=\"T_7ed90_row3_col6\" class=\"data row3 col6\" >Jamaica</td>\n",
       "      <td id=\"T_7ed90_row3_col7\" class=\"data row3 col7\" >Queens</td>\n",
       "      <td id=\"T_7ed90_row3_col8\" class=\"data row3 col8\" >College Point</td>\n",
       "      <td id=\"T_7ed90_row3_col9\" class=\"data row3 col9\" >0.38</td>\n",
       "      <td id=\"T_7ed90_row3_col10\" class=\"data row3 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ed90_level0_row4\" class=\"row_heading level0 row4\" >2844813</th>\n",
       "      <td id=\"T_7ed90_row4_col0\" class=\"data row4 col0\" >2023-01-02 17:01:51-05:00</td>\n",
       "      <td id=\"T_7ed90_row4_col1\" class=\"data row4 col1\" >2023-01-02 17:39:43-05:00</td>\n",
       "      <td id=\"T_7ed90_row4_col2\" class=\"data row4 col2\" >11.50</td>\n",
       "      <td id=\"T_7ed90_row4_col3\" class=\"data row4 col3\" >$18.20</td>\n",
       "      <td id=\"T_7ed90_row4_col4\" class=\"data row4 col4\" >37.9 min</td>\n",
       "      <td id=\"T_7ed90_row4_col5\" class=\"data row4 col5\" >Queens</td>\n",
       "      <td id=\"T_7ed90_row4_col6\" class=\"data row4 col6\" >Forest Hills</td>\n",
       "      <td id=\"T_7ed90_row4_col7\" class=\"data row4 col7\" >Queens</td>\n",
       "      <td id=\"T_7ed90_row4_col8\" class=\"data row4 col8\" >Rosedale</td>\n",
       "      <td id=\"T_7ed90_row4_col9\" class=\"data row4 col9\" >0.44</td>\n",
       "      <td id=\"T_7ed90_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eb9fd20140>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Columns to show for presentation\n",
    "cols = [\n",
    "    'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "    'trip_distance', 'fare_amount', 'trip_duration_min',\n",
    "    'pickup_borough', 'pickup_zone',\n",
    "    'dropoff_borough', 'dropoff_zone',\n",
    "    'predicted_score', 'final_score'\n",
    "]\n",
    "\n",
    "# Sort and select top/bottom\n",
    "top5 = df_scoring.sort_values('final_score', ascending=False).head(5)[cols]\n",
    "bottom5 = df_scoring.sort_values('final_score').head(5)[cols]\n",
    "\n",
    "# Display with styled headers\n",
    "print(\"\\n Top 5 Most Profitable Trips\")\n",
    "display(top5.style.set_caption(\"Top 5 Trips\").format({\n",
    "    'trip_distance': '{:.2f}',\n",
    "    'fare_amount': '${:.2f}',\n",
    "    'trip_duration_min': '{:.1f} min',\n",
    "    'predicted_score': '{:.2f}',\n",
    "    'final_score': '{:.2f}'\n",
    "}))\n",
    "\n",
    "print(\"\\n Bottom 5 Least Profitable Trips\")\n",
    "display(bottom5.style.set_caption(\"Bottom 5 Trips\").format({\n",
    "    'trip_distance': '{:.2f}',\n",
    "    'fare_amount': '${:.2f}',\n",
    "    'trip_duration_min': '{:.1f} min',\n",
    "    'predicted_score': '{:.2f}',\n",
    "    'final_score': '{:.2f}'\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee3f7d",
   "metadata": {},
   "source": [
    "| Column            | Meaning                                                                |\n",
    "| ----------------- | ---------------------------------------------------------------------- |\n",
    "| `predicted_score` | The raw, weighted sum based on the chosen features and their weights. |\n",
    "| `final_score`     | The **normalized version**, scaled between 0 and 1 for comparison.     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed9760",
   "metadata": {},
   "source": [
    "How to Use These Scores:\n",
    "predicted_score is useful if we want to explain how the ride‚Äôs components added up.\n",
    "\n",
    "final_score is the actionable version we can rank or display in the app (e.g., ‚ÄúChoose this ride ‚Äî it scores 0.82!‚Äù)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
