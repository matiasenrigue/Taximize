{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47bb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d9a1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\diksha\\Summer Sem\\DataAnalysis\\Notebooks\n",
      "Loaded file: C:/diksha/Summer Sem/DataAnalysis/Data/cleaned/final_cleaned_jan_feb_2023_taxi_data.csv\n",
      "Initial shape: (5646828, 19)\n",
      "Dataset loaded successfully! Shape: (5646828, 19)\n",
      "Columns: ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_distance', 'fare_amount', 'trip_duration_min', 'pickup_date', 'pickup_hour', 'pickup_day_of_week', 'pickup_borough', 'pickup_zone', 'pickup_service_zone', 'dropoff_borough', 'dropoff_zone', 'dropoff_service_zone', 'fare_per_minute', 'trip_speed', 'trip_speed_mph', 'time_of_day', 'is_weekend']\n",
      "\n",
      "Encoding complete!\n",
      "Encoded dataset shape: (5646828, 33)\n",
      "\n",
      "Newly created columns: ['pickup_borough_Brooklyn', 'pickup_borough_EWR', 'pickup_borough_Manhattan', 'pickup_borough_Queens', 'pickup_borough_Staten Island', 'pickup_borough_Unknown', 'dropoff_borough_Brooklyn', 'dropoff_borough_EWR', 'dropoff_borough_Manhattan', 'dropoff_borough_Queens', 'dropoff_borough_Staten Island', 'dropoff_borough_Unknown', 'pickup_service_zone_Boro Zone', 'pickup_service_zone_EWR', 'pickup_service_zone_Yellow Zone', 'dropoff_service_zone_Boro Zone', 'dropoff_service_zone_EWR', 'dropoff_service_zone_Yellow Zone', 'time_of_day_encoded', 'pickup_zone_target_encoded', 'dropoff_zone_target_encoded']\n",
      "\n",
      "Encoded dataset saved to: ../Data/cleaned/encoded_taxi_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# 1: verify your working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Let user select their local file\n",
    "#Tk().withdraw()  # Hide the root window\n",
    "file_path = askopenfilename(title=\"Select your local finall cleaned taxi data CSV\")\n",
    "\n",
    "# Check and load\n",
    "if not file_path or not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\"File not found or not selected.\")\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Loaded file:\", file_path)\n",
    "    print(\"Initial shape:\", df.shape)\n",
    "print(f\"Dataset loaded successfully! Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "#make function to encode binary, one-hot, and ordinal\n",
    "\n",
    "def base_encode(df):\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # 1. Binary Encoding\n",
    "    df_encoded['is_weekend'] = df_encoded['is_weekend'].astype(int)\n",
    "\n",
    "    # 2. One-Hot Encoding\n",
    "    onehot_cols = ['pickup_borough', 'dropoff_borough', 'pickup_service_zone', 'dropoff_service_zone']\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=onehot_cols, drop_first=True)\n",
    "\n",
    "    # 3. Ordinal Encoding\n",
    "    time_order = { \n",
    "        'Early Morning': 0,\n",
    "        'Morning Rush': 1,\n",
    "        'Midday': 2,\n",
    "        'Evening Rush': 3,\n",
    "        'Night': 4\n",
    "    }\n",
    "    df_encoded['time_of_day_encoded'] = df_encoded['time_of_day'].map(time_order)\n",
    "    df_encoded.drop('time_of_day', axis=1, inplace=True)\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "# Use KFold for safe target encoding\n",
    "\n",
    "def target_encode_zones_cv(df,target_column,zone_columns, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    for col in zone_columns:\n",
    "        new_col = f\"{col}_target_encoded\"\n",
    "        df_encoded[new_col] = np.nan\n",
    "\n",
    "        for train_idx, val_idx in kf.split(df):\n",
    "            train, val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "            means = train.groupby(col)[target_column].mean()\n",
    "            df_encoded.loc[val_idx, new_col] = val[col].map(means)\n",
    "\n",
    "    # drop the original high-cardinality columns to avoid confusion when modeling\n",
    "    df_encoded.drop(columns=zone_columns, inplace=True)\n",
    "    return df_encoded\n",
    "\n",
    "# Run the full encoding pipeline\n",
    "\n",
    "# Base encodings\n",
    "df_encoded = base_encode(df)\n",
    "\n",
    "# Target encoding for pickup/dropoff zones\n",
    "high_cardinality_cols = ['pickup_zone', 'dropoff_zone']\n",
    "df_encoded = target_encode_zones_cv(df_encoded, target_column='fare_per_minute', zone_columns=high_cardinality_cols)\n",
    "\n",
    "print(f\"\\nEncoding complete!\")\n",
    "print(f\"Encoded dataset shape: {df_encoded.shape}\")\n",
    "\n",
    "# Show new encoded columns\n",
    "new_cols = [col for col in df_encoded.columns if col not in df.columns]\n",
    "print(f\"\\nNewly created columns: {new_cols}\")\n",
    "\n",
    "#save the encoded daatset\n",
    "output_path = \"../Data/cleaned/encoded_taxi_data.csv\"\n",
    "df_encoded.to_csv(output_path, index=False)\n",
    "print(f\"\\nEncoded dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1825b0b",
   "metadata": {},
   "source": [
    "## Inital Lightweight Model (baseline)\n",
    "\n",
    "I will start with a lightweight model to start the training testing using the target as fare_per_minute starting with lightGBM and linear regression and evalute with MAE and R sqaured. Come back to this when you can changed the target feature to Elli's effective_earnings_per_min (currently dont know how she added this to make it as target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678075e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\diksha\\Summer Sem\\DataAnalysis\\Notebooks\n",
      "Loaded file: C:/diksha/Summer Sem/DataAnalysis/Data/cleaned/encoded_taxi_data.csv\n",
      "Initial shape: (5646828, 33)\n",
      "Data types after conversion:\n",
      "trip_distance                       float64\n",
      "fare_amount                         float64\n",
      "trip_duration_min                   float64\n",
      "pickup_hour                           int32\n",
      "pickup_day_of_week                    int32\n",
      "fare_per_minute                     float64\n",
      "trip_speed                          float64\n",
      "trip_speed_mph                      float64\n",
      "is_weekend                            int64\n",
      "pickup_borough_Brooklyn                bool\n",
      "pickup_borough_EWR                     bool\n",
      "pickup_borough_Manhattan               bool\n",
      "pickup_borough_Queens                  bool\n",
      "pickup_borough_Staten Island           bool\n",
      "pickup_borough_Unknown                 bool\n",
      "dropoff_borough_Brooklyn               bool\n",
      "dropoff_borough_EWR                    bool\n",
      "dropoff_borough_Manhattan              bool\n",
      "dropoff_borough_Queens                 bool\n",
      "dropoff_borough_Staten Island          bool\n",
      "dropoff_borough_Unknown                bool\n",
      "pickup_service_zone_Boro Zone          bool\n",
      "pickup_service_zone_EWR                bool\n",
      "pickup_service_zone_Yellow Zone        bool\n",
      "dropoff_service_zone_Boro Zone         bool\n",
      "dropoff_service_zone_EWR               bool\n",
      "dropoff_service_zone_Yellow Zone       bool\n",
      "time_of_day_encoded                   int64\n",
      "pickup_zone_target_encoded          float64\n",
      "dropoff_zone_target_encoded         float64\n",
      "pickup_month                          int32\n",
      "pickup_year                           int32\n",
      "dropoff_hour                          int32\n",
      "dropoff_day_of_week                   int32\n",
      "trip_duration_minutes               float64\n",
      "dtype: object\n",
      "\n",
      "Final data types:\n",
      "trip_distance                       float64\n",
      "fare_amount                         float64\n",
      "trip_duration_min                   float64\n",
      "pickup_hour                           int32\n",
      "pickup_day_of_week                    int32\n",
      "fare_per_minute                     float64\n",
      "trip_speed                          float64\n",
      "trip_speed_mph                      float64\n",
      "is_weekend                            int64\n",
      "pickup_borough_Brooklyn                bool\n",
      "pickup_borough_EWR                     bool\n",
      "pickup_borough_Manhattan               bool\n",
      "pickup_borough_Queens                  bool\n",
      "pickup_borough_Staten Island           bool\n",
      "pickup_borough_Unknown                 bool\n",
      "dropoff_borough_Brooklyn               bool\n",
      "dropoff_borough_EWR                    bool\n",
      "dropoff_borough_Manhattan              bool\n",
      "dropoff_borough_Queens                 bool\n",
      "dropoff_borough_Staten Island          bool\n",
      "dropoff_borough_Unknown                bool\n",
      "pickup_service_zone_Boro Zone          bool\n",
      "pickup_service_zone_EWR                bool\n",
      "pickup_service_zone_Yellow Zone        bool\n",
      "dropoff_service_zone_Boro Zone         bool\n",
      "dropoff_service_zone_EWR               bool\n",
      "dropoff_service_zone_Yellow Zone       bool\n",
      "time_of_day_encoded                   int64\n",
      "pickup_zone_target_encoded          float64\n",
      "dropoff_zone_target_encoded         float64\n",
      "pickup_month                          int32\n",
      "pickup_year                           int32\n",
      "dropoff_hour                          int32\n",
      "dropoff_day_of_week                   int32\n",
      "trip_duration_minutes               float64\n",
      "dtype: object\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.220218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2136\n",
      "[LightGBM] [Info] Number of data points in the train set: 4517462, number of used features: 32\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.264910\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l1: 0.160582\tvalid_1's l1: 0.160508\n",
      "[20]\ttraining's l1: 0.104699\tvalid_1's l1: 0.104615\n",
      "[30]\ttraining's l1: 0.0729593\tvalid_1's l1: 0.072898\n",
      "[40]\ttraining's l1: 0.0553102\tvalid_1's l1: 0.055023\n",
      "[50]\ttraining's l1: 0.0460366\tvalid_1's l1: 0.0460246\n",
      "[60]\ttraining's l1: 0.0408308\tvalid_1's l1: 0.0412279\n",
      "[70]\ttraining's l1: 0.0374066\tvalid_1's l1: 0.0380099\n",
      "[80]\ttraining's l1: 0.035307\tvalid_1's l1: 0.0361209\n",
      "[90]\ttraining's l1: 0.0336473\tvalid_1's l1: 0.0346199\n",
      "[100]\ttraining's l1: 0.0323376\tvalid_1's l1: 0.0334396\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's l1: 0.0323376\tvalid_1's l1: 0.0334396\n",
      "\n",
      "ðŸ“Š MAE: 0.033\n",
      "ðŸ“ˆ RÂ² Score: 0.979\n"
     ]
    }
   ],
   "source": [
    "# 1: verify your working directory \n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Let user select their local file\n",
    "#Tk().withdraw()  # Hide the root window\n",
    "file_path = askopenfilename(title=\"Select your local encoded taxi data CSV\")\n",
    "\n",
    "# Check and load\n",
    "if not file_path or not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\"File not found or not selected.\")\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Loaded file:\", file_path)\n",
    "    print(\"Initial shape:\", df.shape)\n",
    "\n",
    "#due to LightGBM needs all features to be numeric, we will ensure all categorical features are encoded properly\n",
    "# Solution 1: Convert datetime columns to numeric features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming your dataframe is named 'df'\n",
    "# Convert datetime columns to datetime type first\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "\n",
    "# Option 1: Extract numeric features from datetime columns\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['pickup_day_of_week'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "df['pickup_month'] = df['tpep_pickup_datetime'].dt.month\n",
    "df['pickup_year'] = df['tpep_pickup_datetime'].dt.year\n",
    "\n",
    "df['dropoff_hour'] = df['tpep_dropoff_datetime'].dt.hour\n",
    "df['dropoff_day_of_week'] = df['tpep_dropoff_datetime'].dt.dayofweek\n",
    "\n",
    "# Calculate trip duration in minutes\n",
    "df['trip_duration_minutes'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Drop the original datetime columns\n",
    "df = df.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'pickup_date'], axis=1)\n",
    "\n",
    "# Check data types to ensure all are numeric\n",
    "print(\"Data types after conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any remaining object columns\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "if len(object_columns) > 0:\n",
    "    print(f\"\\nRemaining object columns: {list(object_columns)}\")\n",
    "    # Handle remaining object columns\n",
    "    for col in object_columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Try to convert to numeric, or encode categorically\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            except:\n",
    "                # If conversion fails, use label encoding\n",
    "                from sklearn.preprocessing import LabelEncoder\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Verify all columns are now numeric\n",
    "print(\"\\nFinal data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Assuming 'target_column' is your target variable name\n",
    "X = df.drop('fare_per_minute', axis=1)  \n",
    "y = df['fare_per_minute']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create LightGBM datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Train the model\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, test_data],\n",
    "    num_boost_round=100,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=10),\n",
    "        log_evaluation(period=10)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n MAE: {mae:.3f}\")\n",
    "print(f\" RÂ² Score: {r2:.3f}\")\n",
    "\n",
    "lgb.plot_importance(model, max_num_features=15, importance_type='gain')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c9a95",
   "metadata": {},
   "source": [
    "Discussion: MAE (Mean Absolute Error) = 0.033\n",
    "This means that the models prediciton are, on avg off only about 0.033 units from the actual values (if prediciting taxi fares in $ then it is off about 3.3 cents on avg if we are looking at trip duration during hours it is off about 2 mins on avg)\n",
    "\n",
    "R sqaured = 0.979\n",
    "This model explains about 97.9 of the variance in our target variables and only about 2.1% reamins unexplained\n",
    "\n",
    "These metrics show that the inital model is performing well! With high accuracy, low error rate\n",
    "\n",
    "Notes: \n",
    "reults being this good might be due to overfitting and that the model memorized the training data rather than learning the patterns\n",
    "\n",
    "could also mean data leakage, will need to check if any features inadvertently contain ingormation about the target that wouldnt be avilable for real-world predictions\n",
    "\n",
    "\n",
    "next steps: Validate the results\n",
    "\n",
    "check fare distributions, what is the typical range for fare_per_minute 2) cross validate across different time periods 3) business logic do the predicitions align with known taxi pricing rules? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27616a",
   "metadata": {},
   "source": [
    "## Linear Regression (baseline model)\n",
    "\n",
    "Next I will use a model that I am used to working with and comapre the results with the LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727ffe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "   MAE: 0.102\n",
      "   RÂ²:  0.777\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = df.drop('fare_per_minute', axis=1)  \n",
    "y = df['fare_per_minute']  \n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop NaNs in X_train and sync y_train\n",
    "X_train_lr = X_train.dropna()\n",
    "y_train_lr = y_train.loc[X_train_lr.index]\n",
    "\n",
    "# Drop NaNs in X_test and sync y_test\n",
    "X_test_lr = X_test.dropna()\n",
    "y_test_lr = y_test.loc[X_test_lr.index]\n",
    "\n",
    "# Train the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_lr, y_train_lr)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_lr)\n",
    "\n",
    "# Evaluate performance\n",
    "mae_lr = mean_absolute_error(y_test_lr, y_pred_lr)\n",
    "r2_lr = r2_score(y_test_lr, y_pred_lr)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"   MAE: {mae_lr:.3f}\")\n",
    "print(f\"   RÂ²:  {r2_lr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30fb43",
   "metadata": {},
   "source": [
    "Discussion for Linear Regression: \n",
    "\n",
    "MAE = 0.102 the predicitions are off by 10.2 cents per min on avg so for a ten minute ride that is about $1.02 error in total fare\n",
    "\n",
    "R Sqaured = 0.777 means this model explains about 77.7% of the variance in fare per minute and that 22.3% of the variation remains unexplained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ad2e0",
   "metadata": {},
   "source": [
    "## Comparision of LightGBM and Linear Regression\n",
    "\n",
    "From basic observation it is shown that LightGBM significantly outperforms Linear Regression due to: \n",
    "\n",
    "1) Non-linear realtionships: taxi fares likely have complex, non-linear patterns that LGBM captures better such as peak hpurs vs off-peak pricing, distance-based rate changes, location-specific surcharges\n",
    "\n",
    "2) Feature Interactions: LGBM automatically finds interactions between features like time of day and location combinations\n",
    "\n",
    "3) Flexiability: LGBM can model complex decision boundaries that linear regression cannot\n",
    "\n",
    "Conclusion:  LightGBM model is substantially better for fare prediction, with 3x better accuracy. The Linear Regression still performs reasonably (RÂ² = 0.777 is decent), but LightGBM's ability to capture complex patterns in taxi pricing makes a better choice.\n",
    "Both models suggest that the feature engineering was effective, but LightGBM better exploits those features!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
